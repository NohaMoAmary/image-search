# Styla 
An AI-Powered outfit recommender system for everyday use addresses the challenge of selecting the right outfit that matches personal style preferences and is appropriate for different occasions. 

# image search
 Search photos on deep fashion dataset using natural language descriptions. The search is powered by OpenAI's CLIP model 
 
## CLIP
is a deep learning model that was developed by OpenAI to understand both images and text at the same time. It can be used for a wide variety of tasks, including image classification, image captioning, and image retrieval. 
CLIP is trained on a large dataset of images and their corresponding text descriptions, which allows it to learn how to associate images with the words that describe them.
 
 
all photos from Deep Fashion Dataset were downloaded and processed with CLIP.

The pre-computed feature vectors for all images can then be used to find the best match to a natural language search query.

## for Deployment 
### using Streamlit and ngrok
 
 ![3](https://user-images.githubusercontent.com/83103904/227759988-ad2a54f3-3cae-4463-a938-c3acdf1b78fa.PNG)
 
 ![5](https://user-images.githubusercontent.com/83103904/227760062-7dd26da9-5d49-42bb-ad7c-7bdb4174a6a0.PNG)
 
 ![1](https://user-images.githubusercontent.com/83103904/227759650-d8cc3362-4e7d-44c5-8664-cccec73ce50d.PNG)

 ![4](https://user-images.githubusercontent.com/83103904/227760024-bebc05b0-846d-4c38-810b-c12bd4ac073a.PNG)

This project was inspired by https://github.com/haltakov/natural-language-image-search 
